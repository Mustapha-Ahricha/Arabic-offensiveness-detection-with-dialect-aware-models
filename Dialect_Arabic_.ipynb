{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fERcWHPBiCbB"
      },
      "source": [
        "\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from time import time\n",
        "from nltk.corpus import stopwords\n",
        "from pandas import read_csv\n",
        "from pandas.plotting import scatter_matrix\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "# from keras.layers import Dense\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from keras.callbacks import TensorBoard\n",
        "# from keras.preprocessing.text import Tokenizer\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from keras.models import Sequential\n",
        "from keras.layers import Dense , Activation , Dropout\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.preprocessing import LabelBinarizer\n",
        "# from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import keras.preprocessing.text\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "4YuPyQsJbRAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuNNPu1oiIoL",
        "outputId": "4bda4d06-fba4-4eba-e058-26ee0f629aa3"
      },
      "source": [
        "# load dataset\n",
        "#\n",
        "import pandas as pd\n",
        "\n",
        "# Charger un fichier JSON dans un DataFrame\n",
        "dataframe = pd.read_json(\"/content/IADD.json\")\n",
        "dataframe.drop_duplicates(inplace=True)\n",
        "\n",
        "# Afficher les premières lignes du DataFrame\n",
        "print(dataframe.head())\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence Region DataSource Country\n",
            "0   : وش فيك تسألني إذا كنت غالي؟  غالي وتسوى من ...    GLF       DART      NA\n",
            "1  روان بن حسين مستحيل ما ادز شي بسناب  حتى لو ما...    GLF       DART      NA\n",
            "2   : ما نسيتك بالدعا والأرض جفاف، وشلون أبنساك و...    GLF       DART      NA\n",
            "3   : فارس_البقميk_محب  أطيب من الطيب واصل الطيب ...    GLF       DART      NA\n",
            "4  شوفو والله ابوها كشخه وصغير احس واضحه الفلوس م...    GLF       DART      NA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher le type de la colonne 'text'\n",
        "print(type(dataframe['Sentence']))"
      ],
      "metadata": {
        "id": "HBqaWbxHQVW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e7ec5a-5030-4664-b9b4-9c1e3b4a2afb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer les colonnes 'Region' et 'DataSource' du DataFrame\n",
        "dataframe.drop(['Region', 'DataSource'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "EbrQak4zTIyz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hdtqqr8iJUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68cca675-205f-4514-9a18-4ef5c86bd893"
      },
      "source": [
        "train_size = int(len(dataframe) * .8)\n",
        "\n",
        "print(int(len(dataframe['Sentence'])))\n",
        "print(train_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127257\n",
            "101805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQIVT349iJY7"
      },
      "source": [
        "texts= dataframe['Sentence']\n",
        "tags = dataframe['Country']\n",
        "\n",
        "\n",
        "train_posts =dataframe['Sentence'][:train_size]\n",
        "train_tags = dataframe['Country'][:train_size]\n",
        "\n",
        "\n",
        "\n",
        "test_posts = dataframe['Sentence'][train_size:]\n",
        "test_tags =  dataframe['Country'][train_size:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzZGt7hQiJcT"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=None,lower=False)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "x_train = tokenizer.texts_to_matrix(train_posts, mode='tfidf')\n",
        "x_test = tokenizer.texts_to_matrix(test_posts, mode='tfidf')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znxc6crCiJe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7983488-eea4-49b1-fb24-1b7a96c1068c"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(tags)\n",
        "tagst=encoder.fit_transform(tags)\n",
        "\n",
        "num_classes = int((len(set(tagst))))\n",
        "print((len(set(tagst))))\n",
        "\n",
        "y_train = encoder.fit_transform(train_tags)\n",
        "y_test = encoder.fit_transform(test_tags)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI5uRIy3iJhz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "53384900-f2dc-4e8c-836e-fe8396a92f90"
      },
      "source": [
        "y_train= keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "num_labels = int(len(y_train.shape))\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "max_words=vocab_size\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c81a76e689af>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrUaeFiziJlL"
      },
      "source": [
        "import keras.backend as K\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "from keras.metrics import Precision , Recall , Accuracy , TruePositives , TrueNegatives , FalsePositives , FalseNegatives\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT7RswjSjUj1"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfNiv5LCjUnM"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['categorical_accuracy','Recall','Precision', f1_metric,'TruePositives','TrueNegatives','FalsePositives','FalseNegatives'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-3RzayTjUss"
      },
      "source": [
        "batch_size = 100\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)\n",
        "\n",
        "\n",
        "model.save('my_model.h1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdiaV7a5jUw0"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# loading\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH4-eWntjU0j"
      },
      "source": [
        "#model = keras.models.load_model('my_model.h1')\n",
        "Evaluation_valus = model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Loss\" , 'categorical_accuracy','Recall','Precision','f1_metric','TruePositives','TrueNegatives','FalsePositives','FalseNegatives')\n",
        "\n",
        "print(Evaluation_valus)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmGMv_lRkWV-"
      },
      "source": [
        "for x in data[\"text\"][:25]:\n",
        "\n",
        "    tokens = tokenizer.texts_to_matrix([x], mode='tfidf')\n",
        "\n",
        "    c=model.predict(np.array(tokens))\n",
        "    cc=model.predict_classes(tokens)\n",
        "    xc = encoder.inverse_transform(cc)\n",
        "\n",
        "\n",
        "    print(c,\"= \\t\",cc,\"\\t\",xc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}